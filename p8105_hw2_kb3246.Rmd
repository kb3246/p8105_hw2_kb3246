---
title: "Data Science HW-2"
author: "Kasturi Bhamidipati"
date: "2022-10-02"
output: github_document
---

First we load the libraries that we need! 
```{r load pacakges}
library(tidyverse)
library(readxl)
library(skimr)
```

# Problem 1

### Importing, cleaning and making changes 

First we read and clean the NYC Transit Subway dataset. Then we want to retain specific variables and convert specific variables as stated in the problem. To that extent, we retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Further, we convert the entry variable from character (YES vs NO) to a logical variable. 

```{r}
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

### Summary of dataset 

Here's a summary of the dataset: 
`r skim(trans_ent)`
- It consists of `r nrow(trans_ent)` rows and `r ncol(trans_ent)` columns. 

- The dataset has 16 character variables, 2 logical variables and 2 numeric variables. 

- Each route in this datatset is represented as a separate variable. It includes other variables such as line, station name, presence of exits, presence of entrance, entrance type, ADA compliance, and if the station has a vending machine. 

- The dataset above is not tidy. We want to make sure to condense route variables to a single variable called route with the lines as entries under it. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. 

### To obtain number of distinct stations

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```
- Therefore, there are 465 distinct stations. 

### To obtain number of ADA compliant stations

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```
- Therefore, the number of stations that are ADA compliant are 84. 

### To compute the proprtion 

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

- Therefore, the proportion of station entrances / exits without vending allow entrance is 0.377. 

### A train stations that are ADA compliant 

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

- Therefore, 60 distinct stations serve the A train and 17 among these are ADA compliant as well. 

# Problem 2

### Reading and cleaning Mr. Trash Wheel 

We want to read and clean the Mr. Trash Wheel dataset:  
```{r Mr. Trash Wheel}
mr_trash_wheel = read_excel("Data/Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N549") %>%
  janitor::clean_names()%>%
  drop_na(dumpster) %>%
  mutate(sports_balls = as.integer(sports_balls), wheel = "mr")
```

### Reading and cleaning Prof. Trash Wheel 

We want to read and clean the Prof. Trash Wheel dataset: 

```{r Prof. Trash Wheel}
prof_trash_wheel = read_excel("Data/Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M96") %>%
  janitor::clean_names()%>%
  drop_na(dumpster) %>%
  mutate(year = as.character(year), wheel = "prof")
```

### Combining the datasets

Now we want to combine the two datasets: 

```{r Combined Trash Wheel}
combined_trash_wheel = bind_rows(mr_trash_wheel, prof_trash_wheel) %>%
  janitor::clean_names()
```

### Summary of the datatsets 
Here is a description of my combined dataset: 

`r skim(combined_trash_wheel)`

- The total number of rows are `r nrow(combined_trash_wheel)` and number of variables are `r ncol(combined_trash_wheel)`

- There are three character variables, eleven numeric variables and one POSIXct variable which is for the date. 

- The total weight of trash collected by Professor Trash Wheel is `r sum(prof_trash_wheel$weight_tons, na.rm = TRUE)`tons

- The total number of sports balls collected by Mr. Trash Wheel in 2020 was `r sum(combined_trash_wheel[which(combined_trash_wheel$year =="2020" & combined_trash_wheel$wheel =="mr"), "sports_balls"])`

# Problem 3

### `pols-mont.csv`: Cleaning the dataset, mutating and dropping variables 

```{r pols-month}
pols_month = read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>%
    mutate(month = month.abb[month], 
           president = case_when(prez_gop==1 ~ "gop", 
                                 prez_dem ==1 ~ "dem")
             )%>%
  select(-prez_dem, -prez_gop, -day)
```

I want to mention here, that while `prez_gop` is meant to be a binary variable, there were some 2s found in the dataset. I do not know the possible explanation for this, but this is something to note. 

### `snp.csv`: Cleaning the dataset, mutating and dropping variables 

```{r snp}
snp = read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE)%>%
  mutate(month = month.abb[month], 
         year = case_when( year<16 ~  year+2000, 
                           year >16 ~ year+1900
    
  )
           ) %>%
  relocate(year) %>%
  select( -day)
```

### `unemployment.csv`: Cleaning the dataset, mutating and dropping variables

```{r unemployment}
unemployment = read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment")
```

### Merging the datasets

First we merge the `pols_month.csv` and `snp.csv` using a left join. 

```{r merge1}
pols_snp = 
  left_join(pols_month, snp)
```

Now we add `unemployemtn.csv` to the above dataset using a left join. 

```{r final merge}
merged_data = 
  left_join(pols_snp, unemployment)
```

### Summary of the individual datasets

#### `pols_month` dataset: 

This is the `pols_month` dataset: 

`r skim(pols_month)`

- It has `r nrow(pols_month)` observations and `r ncol(pols_month)` variables. 

- It gives us information on the number of politicians that are either republican or democratic during a given point in time (years included were `r min(pols_month$year)` to `r max(pols_month$year)`

- The `prez_gop` and `prez_dem` variables indicated whether the president for that date was republican or democratic. 

#### `snp` dataset: 

This is the `snp` dataset: 

`r skim(snp)`

- It has `r nrow(snp)` observations and `r ncol(snp)` variables. 

- It gives us information on the closing values for the stock index during the corresponding date (years included were `r min(snp$year)` to `r max(snp$year)`). 

#### `unemployment` dataset: 

This is the `unemployment` dataset:

`r skim(unemployment)`

- It has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables. 

- It gives us information on the percent of individuals unemployed at the corresponding time-period (year included were `r min(unemployment$year)` to `r max(unemployment$year)`). 

### Summary of merged dataset

This is the `merged_data` dataset: 

`r skim(merged_data)`

- It has `r nrow(merged_data)` observations and `r ncol(merged_data)` variables. 

- Some of the key variables included in this dataset are whether a certain president was a democrat or a republican, the closing stock index price and the percent unemployed during a specific time point (years included were `r min(merged_data$year)` to `r max(merged_data$year)`). 

